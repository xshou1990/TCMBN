{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import transformer.Constants as Constants\n",
    "\n",
    "from preprocess.Dataset import get_dataloader\n",
    "from transformer.Models import Transformer\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def prepare_dataloader(opt):\n",
    "    \"\"\" Load data and prepare dataloader. \"\"\"\n",
    "\n",
    "    def load_data(name, dict_name):\n",
    "        with open(name, 'rb') as f:\n",
    "            data = pickle.load(f, encoding='latin-1')\n",
    "            num_types = data['dim_process']\n",
    "            data = data[dict_name]\n",
    "            return data, int(num_types)\n",
    "\n",
    "    print('[Info] Loading train data...')\n",
    "    train_data, num_types = load_data(opt.data + 'train.pkl', 'train')\n",
    "    print('[Info] Loading dev data...')\n",
    "    dev_data, _ = load_data(opt.data + 'dev.pkl', 'dev')\n",
    "#     print('[Info] Loading test data...')\n",
    "#     test_data, _ = load_data(opt.data + 'test.pkl', 'test')\n",
    "\n",
    "    trainloader = get_dataloader(train_data[0:100], opt.batch_size, shuffle=True)\n",
    "    devloader = get_dataloader(dev_data[0:64], opt.batch_size, shuffle=False)\n",
    "    return trainloader, devloader, num_types\n",
    "\n",
    "\n",
    "def train_epoch(model, training_data, optimizer, opt):\n",
    "    \"\"\" Epoch operation in training phase. \"\"\"\n",
    "\n",
    "    model.train()\n",
    "\n",
    "#     total_event_ll = 0  # cumulative event log-likelihood\n",
    "#     total_time_se = 0  # cumulative time prediction squared-error\n",
    "#     total_event_rate = 0  # cumulative number of correct prediction\n",
    "#     total_num_event = 0  # number of total events\n",
    "#     total_num_pred = 0  # number of predictions\n",
    "    for batch in tqdm(training_data, mininterval=2,\n",
    "                      desc='  - (Training)   ', leave=False):\n",
    "        \"\"\" prepare data \"\"\"\n",
    "        event_time, time_gap, event_type = map(lambda x: x.to(opt.device), batch)\n",
    "\n",
    "        \"\"\" forward \"\"\"\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        event_type_0 = torch.hstack([torch.zeros(event_type.shape[0],1,44).int().to('cpu'),event_type])\n",
    "        \n",
    "        event_time_0 = torch.hstack([torch.zeros(event_time.shape[0],1).int().to('cpu'),event_time])\n",
    "\n",
    "        time_gap_0 = torch.hstack([torch.zeros(time_gap.shape[0],1).int().to('cpu'),time_gap])\n",
    "\n",
    "        enc_out, non_pad_mask = model(event_type_0, event_time_0)\n",
    "        \n",
    "        a,b,c = enc_out[:,:-1,:].shape[0],enc_out[:,:-1,:].shape[1],enc_out[:,:-1,:].shape[2]\n",
    "        \n",
    "\n",
    "        \"\"\" backward \"\"\"\n",
    "        # calculate P*(t_i+1) by mgn : log_loss_time: batch*len x 1\n",
    "        log_loss_time = model.MGN.loss(enc_out[:,:-1,:].reshape(a*b,c), torch.log(time_gap_0[:,1:]+1e-9).reshape(a*b,1))\n",
    "\n",
    "        # calculate P*(y_i+1) by mbn: \n",
    "     #   enc_out_time = torch.cat([enc_out[:,:-1,:], torch.log(time_gap_0[:,1:]+1e-9).unsqueeze(2)],dim=2)\n",
    "        log_loss_type = model.MBN.loss(enc_out[:,:-1,:].reshape(a*b,c), event_type.reshape(a*b,model.num_types) )\n",
    "        # sum log loss\n",
    "        loss = torch.sum((log_loss_time + log_loss_type).reshape(a,b)  * non_pad_mask[:,1:,0])\n",
    "\n",
    "#         loss = torch.sum((log_loss_type).reshape(a,b) * non_pad_mask[:,1:,0])\n",
    "       # print(\"time loss {} type loss {}\".format( torch.sum(log_loss_type.reshape(a,b) * non_pad_mask[:,1:,0]) ,torch.sum(log_loss_time.reshape(a,b) * non_pad_mask[:,1:,0])))\n",
    "              \n",
    "        loss.backward()\n",
    "\n",
    "        \"\"\" update parameters \"\"\"\n",
    "        optimizer.step()\n",
    "\n",
    "        \"\"\" note keeping \"\"\"\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def eval_epoch(model, validation_data, opt):\n",
    "    \"\"\" Epoch operation in evaluation phase. \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    total_ll = 0\n",
    "    total_time_se = 0\n",
    "    total_num_pred = 0\n",
    "    pred_label = []\n",
    "    true_label = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(validation_data, mininterval=2,\n",
    "                          desc='  - (Validation) ', leave=False):\n",
    "            \"\"\" prepare data \"\"\"\n",
    "\n",
    "            event_time, time_gap, event_type = map(lambda x: x.to(opt.device), batch)\n",
    "            \n",
    "            event_type_0 = torch.hstack([torch.zeros(event_type.shape[0],1,44).int().to('cpu'),event_type])\n",
    "\n",
    "            event_time_0 = torch.hstack([torch.zeros(event_time.shape[0],1).int().to('cpu'),event_time])\n",
    "\n",
    "            time_gap_0 = torch.hstack([torch.zeros(time_gap.shape[0],1).int().to('cpu'),time_gap])\n",
    "\n",
    "            enc_out, non_pad_mask = model(event_type_0, event_time_0)\n",
    "\n",
    "            a,b,c = enc_out[:,:-1,:].shape[0],enc_out[:,:-1,:].shape[1],enc_out[:,:-1,:].shape[2]\n",
    "\n",
    "\n",
    "            # calculate P*(t_i+1) by mgn : log_loss_time: batch*len x 1\n",
    "            log_loss_time = model.MGN.loss(enc_out[:,:-1,:].reshape(a*b,c), torch.log(time_gap_0[:,1:]+1e-9).reshape(a*b,1))\n",
    "            \n",
    "            log_timegap = model.MGN.mean(enc_out[:,:-1,:].reshape(a*b,c))\n",
    "            \n",
    "            diff = torch.exp(log_timegap) - time_gap.reshape(a*b,)\n",
    "            se = torch.sum(diff * diff)\n",
    "            \n",
    "            # calculate P*(y_i+1) by mbn: \n",
    "            log_loss_type = model.MBN.loss(enc_out[:,:-1,:].reshape(a*b,c), event_type.reshape(a*b,model.num_types))\n",
    "            \n",
    "            pred_type = model.MBN.predict(enc_out[:,:-1,:].reshape(a*b,c) )[(non_pad_mask[:,1:,:].repeat(1,1, model.num_types)==1).reshape(a*b,model.num_types)]\n",
    "            \n",
    "            pred_label += list(pred_type.cpu().numpy())\n",
    "\n",
    "            true_type = event_type[(non_pad_mask[:,1:,:].repeat(1,1, model.num_types)==1)] #.reshape(a*b,model.num_types).flatten()\n",
    "           \n",
    "            true_label += list(true_type.cpu().numpy())\n",
    "           \n",
    "            \n",
    "            #  log loss\n",
    "            loss = torch.sum((log_loss_time + log_loss_type).reshape(a,b) * non_pad_mask[:,1:,0])\n",
    "\n",
    "\n",
    "            \"\"\" note keeping \"\"\"\n",
    "            total_ll += loss.item()\n",
    "            total_time_se += se.item()\n",
    "            total_num_pred += event_time.ne(Constants.PAD).sum().item() - event_time.shape[0]\n",
    "\n",
    "                  \n",
    "    roc_auc = roc_auc_score(y_true=true_label, y_score=pred_label,multi_class='ovo', average=\"samples\")\n",
    "    rmse = np.sqrt(total_time_se / total_num_pred)\n",
    "    \n",
    "    return total_ll, roc_auc, rmse\n",
    "\n",
    "def train(model, training_data, validation_data, optimizer, scheduler, opt):\n",
    "    \"\"\" Start training. \"\"\"\n",
    "\n",
    "\n",
    "    for epoch_i in range(opt.epoch):\n",
    "        epoch = epoch_i + 1\n",
    "        print('[ Epoch', epoch, ']')\n",
    "\n",
    "        start = time.time()\n",
    "        train_event = train_epoch(model, training_data, optimizer, opt)\n",
    "        print('  - (Train)    negative loglikelihood: {ll: 8.4f}, '\n",
    "              'elapse: {elapse:3.3f} min'\n",
    "              .format(ll=train_event, elapse=(time.time() - start) / 60))\n",
    "\n",
    "        start = time.time()\n",
    "        valid_event, type_ll_seq, time_ll = eval_epoch(model, validation_data, opt)\n",
    "        print('  - (dev)    nll: {ll: 8.4f}, '\n",
    "              ' roc_auc :{type:8.4f},'\n",
    "              'rmse :{time:8.4},'\n",
    "              'elapse: {elapse:3.3f} min'\n",
    "              \n",
    "              .format(ll=valid_event, type=type_ll_seq,time=time_ll, elapse=(time.time() - start) / 60))\n",
    "\n",
    "#         print('  - [Info] Maximum ll: {event: 8.5f}, '\n",
    "#               'Maximum accuracy: {pred: 8.5f}, Minimum RMSE: {rmse: 8.5f}'\n",
    "#               .format(event=max(valid_event_losses), pred=max(valid_pred_losses), rmse=min(valid_rmse)))\n",
    "\n",
    "        # logging\n",
    "#         with open(opt.log, 'a') as f:\n",
    "#             f.write('{epoch}, {ll: 8.5f}, {acc: 8.5f}, {rmse: 8.5f}\\n'\n",
    "#                     .format(epoch=epoch, ll=valid_event, acc=valid_type, rmse=valid_time))\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "\n",
    "# def main():\n",
    "#     \"\"\" Main function. \"\"\"\n",
    "\n",
    "#     parser = argparse.ArgumentParser()\n",
    "\n",
    "#     parser.add_argument('-data', required=True)\n",
    "\n",
    "#     parser.add_argument('-epoch', type=int, default=30)\n",
    "#     parser.add_argument('-batch_size', type=int, default=16)\n",
    "\n",
    "#     parser.add_argument('-d_model', type=int, default=64)\n",
    "#     parser.add_argument('-d_inner_hid', type=int, default=128)\n",
    "#     parser.add_argument('-d_k', type=int, default=16)\n",
    "#     parser.add_argument('-d_v', type=int, default=16)\n",
    "\n",
    "#     parser.add_argument('-n_head', type=int, default=4)\n",
    "#     parser.add_argument('-n_layers', type=int, default=4)\n",
    "\n",
    "#     parser.add_argument('-dropout', type=float, default=0.1)\n",
    "#     parser.add_argument('-lr', type=float, default=1e-4)\n",
    "\n",
    "#     parser.add_argument('-log', type=str, default='log.txt')\n",
    "\n",
    " \n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.argv=['']\n",
    "del sys\n",
    "import argparse\n",
    "\n",
    "parsed_args = argparse.ArgumentParser()\n",
    "parsed_args.device = 1\n",
    "parsed_args.data = \"data/dunnhumby/split_1/\"\n",
    "parsed_args.batch_size = 32\n",
    "parsed_args.n_head = 4\n",
    "parsed_args.n_layers = 4\n",
    "parsed_args.d_model = 64\n",
    "parsed_args.d_inner = 32\n",
    "parsed_args.d_k=32\n",
    "parsed_args.d_v=32\n",
    "parsed_args.ber_comps = 12\n",
    "parsed_args.gau_comps = 12\n",
    "parsed_args.dropout=0.1\n",
    "parsed_args.lr=1e-3\n",
    "parsed_args.epoch=1\n",
    "parsed_args.log='log.txt'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] parameters: ArgumentParser(prog='', usage=None, description=None, formatter_class=<class 'argparse.HelpFormatter'>, conflict_handler='error', add_help=True)\n",
      "[Info] Loading train data...\n",
      "[Info] Loading dev data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  - (Training)   :   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Number of parameters: 206016\n",
      "[ Epoch 1 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  - (Validation) :   0%|          | 0/2 [00:00<?, ?it/s]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Train)    negative loglikelihood:  8426.4121, elapse: 0.050 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (dev)    nll:  234033.9297,  nll per seq :  0.6915,nll by time :   10.76,elapse: 0.030 min\n"
     ]
    }
   ],
   "source": [
    "opt = parsed_args\n",
    "\n",
    "# default device is CUDA\n",
    "opt.device = torch.device('cpu')\n",
    "\n",
    "#     # setup the log file\n",
    "#     with open(opt.log, 'w') as f:\n",
    "#         f.write('Epoch, Log-likelihood, Accuracy, RMSE\\n')\n",
    "\n",
    "print('[Info] parameters: {}'.format(opt))\n",
    "\n",
    "\"\"\" prepare dataloader \"\"\"\n",
    "trainloader, testloader, num_types = prepare_dataloader(opt)\n",
    "\n",
    "\"\"\" prepare model \"\"\"\n",
    "model = Transformer(\n",
    "    num_types=num_types,\n",
    "    d_model=opt.d_model,\n",
    "    d_inner=opt.d_inner,\n",
    "    n_layers=opt.n_layers,\n",
    "    n_head=opt.n_head,\n",
    "    d_k=opt.d_k,\n",
    "    d_v=opt.d_v,\n",
    "    b_comps=opt.ber_comps,\n",
    "    g_comps=opt.gau_comps,\n",
    "    dropout=opt.dropout,\n",
    ")\n",
    "model.to(opt.device)\n",
    "\n",
    "\"\"\" optimizer and scheduler \"\"\"\n",
    "optimizer = optim.Adam(filter(lambda x: x.requires_grad, model.parameters()),\n",
    "                       opt.lr, betas=(0.9, 0.999), eps=1e-05)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, 10, gamma=0.9)\n",
    "\n",
    "\n",
    "\"\"\" number of parameters \"\"\"\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print('[Info] Number of parameters: {}'.format(num_params))\n",
    "\n",
    "\"\"\" train the model \"\"\"\n",
    "train(model, trainloader, testloader, optimizer, scheduler, opt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.MGN.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Normal, OneHotCategorical\n",
    "m = Categorical(torch.tensor([ 0.25, 0.25, 0.25, 0.25 ]))\n",
    "m.sample()  # equal probability of 0, 1, 2, 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (health3)",
   "language": "python",
   "name": "health3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
